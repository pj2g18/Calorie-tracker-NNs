{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933dff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29856837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight-2021-03-05.json']\n",
      "[15.30000019 14.6        13.89999962 13.19999981 13.19999981 14.60000038\n",
      " 14.60000038 14.60000038 13.89999962 13.89999962 13.89999962 14.60000038\n",
      " 14.60000038 13.19999981 13.19999981]\n",
      "[114.6 114.6 112.  112.8 112.8 112.  112.2 110.  110.8 109.8 109.8 110.4\n",
      " 107.6 109.8 108.7]\n"
     ]
    }
   ],
   "source": [
    "#GET FAT AND WEIGHT DATA\n",
    "\n",
    "#things to fill out\n",
    "rootdir = \"maddy driscoll/MyFitbitData5/Mad/personal & Account\"\n",
    "regex = re.compile('weight-2021-03-05')\n",
    "startDate = '03/13/21' \n",
    "endDate = '03/28/21'\n",
    "\n",
    "#get time period\n",
    "startd = datetime.datetime.strptime(startDate, \"%m/%d/%y\")\n",
    "endd = datetime.datetime.strptime(endDate, \"%m/%d/%y\")#\n",
    "\n",
    "#gets range of dates between start and end\n",
    "date_array = (startd + datetime.timedelta(days=x) for x in range(0, (endd-startd).days))\n",
    "dates = []\n",
    "for date_object in date_array:\n",
    "    #gets date value as string\n",
    "    dates = np.append(dates, date_object.strftime(\"%m/%d/%y\"))\n",
    "\n",
    "    \n",
    "#get weight files\n",
    "filenames = os.listdir(rootdir)\n",
    "weights= []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            weights = np.append(weights, file)\n",
    "print(weights)            \n",
    "\n",
    "\n",
    "#get weight data\n",
    "roughdata = []\n",
    "for x in range(np.size(weights)):\n",
    "    filename = rootdir + \"/\" + weights[x]    \n",
    "    data = []\n",
    "    weight = []\n",
    "    fat = []\n",
    "    with open(filename) as json_file:\n",
    "        rawdata = json.load(json_file)\n",
    "        \n",
    "        #checks if data is within start and end date\n",
    "        for n in range(np.size(rawdata)):\n",
    "            date = rawdata[n][\"date\"]\n",
    "            if date in dates:\n",
    "                roughdata.append(rawdata[n])  \n",
    "                \n",
    "        #delete irrelevant information then save relevant info\n",
    "        for x in range(np.size(roughdata)):    \n",
    "            del roughdata[x][\"logId\"]\n",
    "            del roughdata[x][\"time\"]\n",
    "            del roughdata[x][\"source\"]\n",
    "            del roughdata[x][\"bmi\"]\n",
    "            weight = np.append(weight, roughdata[x][\"weight\"])\n",
    "            fat = np.append(fat, roughdata[x][\"fat\"])\n",
    "\n",
    "        data = np.append(data, roughdata)\n",
    "\n",
    "print(fat)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2173619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1052.]\n",
      " [ 932.]\n",
      " [ 601.]\n",
      " [ 810.]\n",
      " [ 775.]\n",
      " [ 757.]\n",
      " [1021.]\n",
      " [2191.]\n",
      " [ 658.]\n",
      " [ 744.]\n",
      " [1097.]\n",
      " [ 632.]\n",
      " [ 857.]\n",
      " [1611.]\n",
      " [1261.]]\n"
     ]
    }
   ],
   "source": [
    "#GET CALORIE DATA\n",
    "\n",
    "#things to fill out\n",
    "rootdir = \"maddy driscoll/MyFitbitData5/Mad/Nutrition\"\n",
    "regex = re.compile('food_logs-0')\n",
    "startD = \"2021-03-12\"\n",
    "endD = \"2021-03-27\"\n",
    "\n",
    "#get calorie files\n",
    "filenames = os.listdir(rootdir)\n",
    "foodfiles = []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            foodfiles = np.append(foodfiles, file)\n",
    "\n",
    "\n",
    "#start boolean for when data is within date range\n",
    "start = False\n",
    "\n",
    "#get food entries\n",
    "for x in range(np.size(foodfiles)):\n",
    "    filename = rootdir + \"/\" + foodfiles[x]\n",
    "    data = []\n",
    "    count = 0\n",
    "    \n",
    "    with open(filename) as json_file:\n",
    "        roughdata = json.load(json_file)\n",
    "        for y in range(np.size(roughdata)):\n",
    "            if roughdata[y-count][\"logDate\"] == startD:\n",
    "                start = False\n",
    "            if roughdata[y-count][\"logDate\"] == endD:\n",
    "                start = True\n",
    "                \n",
    "            #once within date range:\n",
    "            if start == True:\n",
    "                #delete irrelevant informaiton and track calorie information\n",
    "                cal = roughdata[y-count][\"loggedFood\"][\"calories\"]                \n",
    "                del roughdata[y-count][\"logId\"]\n",
    "                del roughdata[y-count][\"loggedFood\"]\n",
    "                del roughdata[y-count][\"favorite\"]\n",
    "                #if the data contains extra nutritionalvalues data slot, delete that also\n",
    "                if \"nutritionalValues\" in roughdata[y-count].keys():                \n",
    "                    del roughdata[y-count][\"nutritionalValues\"]                \n",
    "                roughdata[y-count][\"calories\"] = cal\n",
    "            else:\n",
    "                #delete data outside of date range\n",
    "                del roughdata[y-count]\n",
    "                count +=1\n",
    "        \n",
    "        data = np.append(data, roughdata)\n",
    "           \n",
    "#get calories for each day\n",
    "calories = data[0][\"calories\"]\n",
    "totCalories = np.empty((0,1))\n",
    "dates = np.empty((0,1))\n",
    "\n",
    "\n",
    "for x in range(1, len(data)):\n",
    "    \n",
    "    #if next food entry is from the same date\n",
    "    if data[x-1][\"logDate\"] == data[x][\"logDate\"]:\n",
    "        \n",
    "        #add to calorie counter for the day\n",
    "        calories += data[x][\"calories\"]\n",
    "        \n",
    "        #add to list of calories per day if at end of loop\n",
    "        if x == len(data)-1:\n",
    "            totCalories = np.vstack((totCalories, calories))\n",
    "    #add to list of calories per day if new day\n",
    "    else:\n",
    "        dates = np.vstack((dates, data[x-1][\"logDate\"]))\n",
    "        totCalories = np.vstack((totCalories, calories))\n",
    "        calories = data[x][\"calories\"]\n",
    "    \n",
    "totCalories = np.flip(totCalories)\n",
    "print(totCalories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1648382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-142.30229677 -615.3131631    91.65866162   -0.          488.58337522\n",
      "   58.17978814 -273.61167113   95.13531859 -121.76220858   -0.\n",
      "  360.84063081 -348.23303598  367.29365004 -131.07102722    0.        ]\n",
      "[1194.30229677 1547.3131631   509.34133838  810.          286.41662478\n",
      "  698.82021186 1294.61167113 2095.86468141  779.76220858  744.\n",
      "  736.15936919  980.23303598  489.70634996 1742.07102722 1261.        ]\n"
     ]
    }
   ],
   "source": [
    "#GET RELATIVE CALORIE DATA\n",
    "\n",
    "#calculate calories burned more/less than consumed based on weight change\n",
    "def caloriesBurned(weight, fat):\n",
    "    fatMass = []\n",
    "    leanMass = []\n",
    "    for x in range(len(weight)):\n",
    "        fatMass = np.append(fatMass, weight[x]*fat[x]/100)\n",
    "        leanMass = np.append(leanMass, weight[x] - fatMass[x])\n",
    "    calories = [] \n",
    "    for x in range(len(weight) - 1):   \n",
    "        calories = np.append(calories, -(fatMass[x]-fatMass[x+1])*442.39)\n",
    "        if leanMass[x] >= leanMass[x+1]:\n",
    "            calories[x] -= (leanMass[x] - leanMass[x+1])*70\n",
    "        else:\n",
    "            calories[x] -= (leanMass[x]-leanMass[x+1])*265\n",
    "    calories = np.append(calories, [0])\n",
    "\n",
    "    return calories\n",
    "        \n",
    "#calculate total calories burned in a day\n",
    "calories = caloriesBurned(weight, fat)\n",
    "print(calories)\n",
    "for x in range(len(calories)):\n",
    "    calories[x] = totCalories[x] - calories[x]\n",
    "\n",
    "#calories = np.append(calories, [2000,2000, 2000])\n",
    "print(calories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc82e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5256, 3])\n",
      "tensor([[ 0.9531, -0.9108, -1.0000],\n",
      "        [ 0.9440, -0.8672, -1.0000],\n",
      "        [ 0.9443, -0.9345, -1.0000],\n",
      "        ...,\n",
      "        [ 0.9445, -0.7859,  1.0000],\n",
      "        [ 0.9440, -0.8068,  1.0000],\n",
      "        [ 0.9440, -0.8186,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "#things to fill in\n",
    "rootdir = \"maddy driscoll/MyFitbitData5/Mad/Physical Activity\"\n",
    "regex = re.compile('heart_rate-2021-03-([1][3-9]|[2][0-7])')\n",
    "#get heart rates\n",
    "\n",
    "filenames = os.listdir(rootdir)\n",
    "heartRates = []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            heartRates = np.append(heartRates, file)\n",
    "\n",
    "#read files for hr data\n",
    "inputs = np.empty((0,3))\n",
    "newInput = np.empty(3)\n",
    "dateTime = []\n",
    "start = False\n",
    "minInputs = np.empty((0,3))\n",
    "hrDates = np.empty((0,1))\n",
    "\n",
    "date = startDate\n",
    "inputs = np.empty((0, 3))\n",
    "tempInputs = np.empty((0, 3))\n",
    "count = 0\n",
    "\n",
    "\n",
    "#read heart rate data files\n",
    "for x in range(np.size(heartRates)):\n",
    "    filename = rootdir + \"/\" + heartRates[x]\n",
    "    data = []\n",
    "    with open(filename) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        tempInputs = np.empty((len(data), 3))\n",
    "        \n",
    "        #get inputs from heart rate files\n",
    "        for y in range(len(data)):  \n",
    "            #get time of data recording\n",
    "            temp = data[y][\"dateTime\"][9:] \n",
    "            #convert time input to seconds through the day\n",
    "            tempInputs[y][0] = int(temp[:2])*3600  + int(temp[3:5])*60 + int(temp[6:9])\n",
    "            tempInputs[y][1] = int(data[y][\"value\"][\"bpm\"])\n",
    "            #set third input to day of recording\n",
    "            tempInputs[y][2] = x\n",
    "        if x == 0:\n",
    "            inputs = tempInputs\n",
    "        else:\n",
    "            #add data recording to list of data records\n",
    "            inputs = np.vstack((inputs, tempInputs))\n",
    "\n",
    "\n",
    "for x in range(5):\n",
    "    condensedInputs =[]\n",
    "    for y in range(1, len(inputs), 2):    \n",
    "        if inputs[y][2] == inputs[y-1][2]:\n",
    "            groupInput = inputs[y] + inputs[y-1]\n",
    "            groupInput[1] = groupInput[1]/2\n",
    "            groupInput[2] = groupInput[2]/2\n",
    "            condensedInputs.append(groupInput)\n",
    "    inputs = condensedInputs\n",
    "\n",
    "day = 0\n",
    "splitInputs = []\n",
    "lastSplit = 0\n",
    "for x in range(len(inputs)):\n",
    "    if inputs[x][2] != day:\n",
    "        splitInputs.append(x - lastSplit)\n",
    "        lastSplit = x\n",
    "        day +=1\n",
    "\n",
    "splitInputs.append(len(inputs) - lastSplit)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "for x in range(len(inputs)):\n",
    "    if x < len(inputs)-1:\n",
    "        inputs[x][0] = inputs[x+1][0] - inputs[x][0]\n",
    "inputs = np.delete(inputs, len(inputs)-1, 0)\n",
    "splitInputs[len(splitInputs)-1] -=1\n",
    "\n",
    "\n",
    "\n",
    "#normalize, scale and format\n",
    "\n",
    "train_data_normalized2 = scaler.fit_transform(np.transpose(inputs)[1] .reshape(-1,1))\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "train_data_normalized1 = scaler.fit_transform(np.transpose(inputs)[0] .reshape(-1,1))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "train_data_normalized3 = scaler.fit_transform(np.transpose(inputs)[2] .reshape(-1,1))\n",
    "\n",
    "train_data_normalized = np.hstack((train_data_normalized1, train_data_normalized2))\n",
    "\n",
    "train_data_normalized = np.hstack((train_data_normalized, train_data_normalized3))\n",
    "\n",
    "\n",
    "inputs = torch.FloatTensor(train_data_normalized)\n",
    "numOfInputs = np.size(np.transpose(inputs)[0])\n",
    "print(np.shape(inputs))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bad98be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1])\n",
      "torch.Size([15, 1])\n",
      "tensor([[ 0.0035],\n",
      "        [ 0.3937],\n",
      "        [-0.7536],\n",
      "        [-0.4213],\n",
      "        [-1.0000],\n",
      "        [-0.5442],\n",
      "        [ 0.1144],\n",
      "        [ 1.0000],\n",
      "        [-0.4547],\n",
      "        [-0.4942],\n",
      "        [-0.5029],\n",
      "        [-0.2331],\n",
      "        [-0.7753],\n",
      "        [ 0.6089],\n",
      "        [ 0.0772]])\n"
     ]
    }
   ],
   "source": [
    "#calculate expected outputs\n",
    "y_actual = []\n",
    "day = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "normalized_y = torch.FloatTensor(scaler.fit_transform(calories .reshape(-1,1)))\n",
    "print(np.shape(normalized_y))\n",
    "\n",
    "outputs = normalized_y\n",
    "print(np.shape(outputs))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a169904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size = 3, hidden_size = 50, output_size = 1):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.in2output = nn.Linear(input_size + hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state):\n",
    "        combined = torch.cat((x, hidden_state), 1)\n",
    "        hidden = torch.sigmoid(self.in2hidden(combined))\n",
    "        output = self.in2output(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac3e323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyRNN(\n",
      "  (in2hidden): Linear(in_features=53, out_features=50, bias=True)\n",
      "  (in2output): Linear(in_features=53, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = MyRNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00b3ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\.conda\\envs\\ailab\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.1)   # optimize all cnn parameters\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc26418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.3529\n",
      "Epoch:  1 | train loss: 0.2394\n",
      "Epoch:  2 | train loss: 0.0013\n",
      "Epoch:  3 | train loss: 0.0242\n",
      "Epoch:  4 | train loss: 0.0010\n",
      "Epoch:  5 | train loss: 0.0035\n",
      "Epoch:  6 | train loss: 0.0036\n",
      "Epoch:  7 | train loss: 0.0029\n",
      "Epoch:  8 | train loss: 0.0039\n",
      "Epoch:  9 | train loss: 0.0032\n",
      "Epoch:  10 | train loss: 0.0035\n",
      "Epoch:  11 | train loss: 0.0032\n",
      "Epoch:  12 | train loss: 0.0032\n",
      "Epoch:  13 | train loss: 0.0032\n",
      "Epoch:  14 | train loss: 0.0032\n",
      "Epoch:  15 | train loss: 0.0032\n",
      "Epoch:  16 | train loss: 0.0031\n",
      "Epoch:  17 | train loss: 0.0031\n",
      "Epoch:  18 | train loss: 0.0031\n",
      "Epoch:  19 | train loss: 0.0031\n",
      "Epoch:  20 | train loss: 0.0031\n",
      "Epoch:  21 | train loss: 0.0031\n",
      "Epoch:  22 | train loss: 0.0031\n",
      "Epoch:  23 | train loss: 0.0031\n",
      "Epoch:  24 | train loss: 0.0031\n",
      "Epoch:  25 | train loss: 0.0031\n",
      "Epoch:  26 | train loss: 0.0031\n",
      "Epoch:  27 | train loss: 0.0031\n",
      "Epoch:  28 | train loss: 0.0031\n",
      "Epoch:  29 | train loss: 0.0031\n",
      "Epoch:  30 | train loss: 0.0031\n",
      "Epoch:  31 | train loss: 0.0031\n",
      "Epoch:  32 | train loss: 0.0031\n",
      "Epoch:  33 | train loss: 0.0031\n",
      "Epoch:  34 | train loss: 0.0031\n",
      "Epoch:  35 | train loss: 0.0030\n",
      "Epoch:  36 | train loss: 0.0030\n",
      "Epoch:  37 | train loss: 0.0030\n",
      "Epoch:  38 | train loss: 0.0030\n",
      "Epoch:  39 | train loss: 0.0030\n",
      "Epoch:  40 | train loss: 0.0030\n",
      "Epoch:  41 | train loss: 0.0030\n",
      "Epoch:  42 | train loss: 0.0030\n",
      "Epoch:  43 | train loss: 0.0030\n",
      "Epoch:  44 | train loss: 0.0031\n",
      "Epoch:  45 | train loss: 0.0031\n",
      "Epoch:  46 | train loss: 0.0031\n",
      "Epoch:  47 | train loss: 0.0031\n",
      "Epoch:  48 | train loss: 0.0032\n",
      "Epoch:  49 | train loss: 0.0032\n",
      "Epoch:  50 | train loss: 0.0033\n",
      "Epoch:  51 | train loss: 0.0034\n",
      "Epoch:  52 | train loss: 0.0035\n",
      "Epoch:  53 | train loss: 0.0036\n",
      "Epoch:  54 | train loss: 0.0038\n",
      "Epoch:  55 | train loss: 0.0040\n",
      "Epoch:  56 | train loss: 0.0042\n",
      "Epoch:  57 | train loss: 0.0045\n",
      "Epoch:  58 | train loss: 0.0049\n",
      "Epoch:  59 | train loss: 0.0055\n",
      "Epoch:  60 | train loss: 0.0063\n",
      "Epoch:  61 | train loss: 0.0079\n",
      "Epoch:  62 | train loss: 0.0109\n",
      "Epoch:  63 | train loss: 0.2166\n",
      "Epoch:  64 | train loss: 0.0001\n",
      "Epoch:  65 | train loss: 0.0159\n",
      "Epoch:  66 | train loss: 0.0393\n",
      "Epoch:  67 | train loss: 0.0002\n",
      "Epoch:  68 | train loss: 0.0469\n",
      "Epoch:  69 | train loss: 0.0001\n",
      "Epoch:  70 | train loss: 0.0023\n",
      "Epoch:  71 | train loss: 0.0025\n",
      "Epoch:  72 | train loss: 0.0039\n",
      "Epoch:  73 | train loss: 0.0039\n",
      "Epoch:  74 | train loss: 0.0032\n",
      "Epoch:  75 | train loss: 0.0046\n",
      "Epoch:  76 | train loss: 0.0047\n",
      "Epoch:  77 | train loss: 0.0037\n",
      "Epoch:  78 | train loss: 0.0030\n",
      "Epoch:  79 | train loss: 0.0034\n",
      "Epoch:  80 | train loss: 0.0036\n",
      "Epoch:  81 | train loss: 0.0035\n",
      "Epoch:  82 | train loss: 0.0033\n",
      "Epoch:  83 | train loss: 0.0033\n",
      "Epoch:  84 | train loss: 0.0033\n",
      "Epoch:  85 | train loss: 0.0033\n",
      "Epoch:  86 | train loss: 0.0052\n",
      "Epoch:  87 | train loss: 0.0006\n",
      "Epoch:  88 | train loss: 0.0046\n",
      "Epoch:  89 | train loss: 0.0015\n",
      "Epoch:  90 | train loss: 0.0084\n",
      "Epoch:  91 | train loss: 0.0017\n",
      "Epoch:  92 | train loss: 0.0076\n",
      "Epoch:  93 | train loss: 0.0012\n",
      "Epoch:  94 | train loss: 0.0133\n",
      "Epoch:  95 | train loss: 0.0032\n",
      "Epoch:  96 | train loss: 0.0101\n",
      "Epoch:  97 | train loss: 0.0023\n",
      "Epoch:  98 | train loss: 0.0137\n",
      "Epoch:  99 | train loss: 0.0010\n",
      "Epoch:  100 | train loss: 0.0416\n",
      "Epoch:  101 | train loss: 0.0295\n",
      "Epoch:  102 | train loss: 0.0122\n",
      "Epoch:  103 | train loss: 0.0144\n",
      "Epoch:  104 | train loss: 0.0159\n",
      "Epoch:  105 | train loss: 0.0001\n",
      "Epoch:  106 | train loss: 0.0478\n",
      "Epoch:  107 | train loss: 0.0913\n",
      "Epoch:  108 | train loss: 0.0284\n",
      "Epoch:  109 | train loss: 0.0358\n",
      "Epoch:  110 | train loss: 0.0524\n",
      "Epoch:  111 | train loss: 0.0349\n",
      "Epoch:  112 | train loss: 0.0913\n",
      "Epoch:  113 | train loss: 0.0532\n",
      "Epoch:  114 | train loss: 0.1703\n",
      "Epoch:  115 | train loss: 1.7631\n",
      "Epoch:  116 | train loss: 0.0468\n",
      "Epoch:  117 | train loss: 0.0176\n",
      "Epoch:  118 | train loss: 0.1363\n",
      "Epoch:  119 | train loss: 0.0902\n",
      "Epoch:  120 | train loss: 0.0089\n",
      "Epoch:  121 | train loss: 0.0021\n",
      "Epoch:  122 | train loss: 0.0016\n",
      "Epoch:  123 | train loss: 0.0010\n",
      "Epoch:  124 | train loss: 0.0006\n",
      "Epoch:  125 | train loss: 0.0001\n",
      "Epoch:  126 | train loss: 0.0000\n",
      "Epoch:  127 | train loss: 0.0000\n",
      "Epoch:  128 | train loss: 0.0001\n",
      "Epoch:  129 | train loss: 0.0003\n",
      "Epoch:  130 | train loss: 0.0005\n",
      "Epoch:  131 | train loss: 0.0008\n",
      "Epoch:  132 | train loss: 0.0011\n",
      "Epoch:  133 | train loss: 0.0014\n",
      "Epoch:  134 | train loss: 0.0017\n",
      "Epoch:  135 | train loss: 0.0021\n",
      "Epoch:  136 | train loss: 0.0025\n",
      "Epoch:  137 | train loss: 0.0029\n",
      "Epoch:  138 | train loss: 0.0033\n",
      "Epoch:  139 | train loss: 0.0038\n",
      "Epoch:  140 | train loss: 0.0043\n",
      "Epoch:  141 | train loss: 0.0049\n",
      "Epoch:  142 | train loss: 0.0057\n",
      "Epoch:  143 | train loss: 0.0067\n",
      "Epoch:  144 | train loss: 0.0079\n",
      "Epoch:  145 | train loss: 0.0093\n",
      "Epoch:  146 | train loss: 0.0112\n",
      "Epoch:  147 | train loss: 0.0135\n",
      "Epoch:  148 | train loss: 0.0159\n",
      "Epoch:  149 | train loss: 0.0647\n",
      "Epoch:  150 | train loss: 0.0362\n",
      "Epoch:  151 | train loss: 0.1664\n",
      "Epoch:  152 | train loss: 0.1081\n",
      "Epoch:  153 | train loss: 0.0123\n",
      "Epoch:  154 | train loss: 0.0048\n",
      "Epoch:  155 | train loss: 0.0081\n",
      "Epoch:  156 | train loss: 0.0187\n",
      "Epoch:  157 | train loss: 0.0077\n",
      "Epoch:  158 | train loss: 0.0127\n",
      "Epoch:  159 | train loss: 0.0125\n",
      "Epoch:  160 | train loss: 0.0157\n",
      "Epoch:  161 | train loss: 0.0136\n",
      "Epoch:  162 | train loss: 0.0699\n",
      "Epoch:  163 | train loss: 0.0129\n",
      "Epoch:  164 | train loss: 0.0088\n",
      "Epoch:  165 | train loss: 0.0068\n",
      "Epoch:  166 | train loss: 0.0110\n",
      "Epoch:  167 | train loss: 0.0080\n",
      "Epoch:  168 | train loss: 0.0082\n",
      "Epoch:  169 | train loss: 0.0087\n",
      "Epoch:  170 | train loss: 0.0071\n",
      "Epoch:  171 | train loss: 0.0082\n",
      "Epoch:  172 | train loss: 0.0048\n",
      "Epoch:  173 | train loss: 0.0103\n",
      "Epoch:  174 | train loss: 0.0021\n",
      "Epoch:  175 | train loss: 0.0862\n",
      "Epoch:  176 | train loss: 0.0027\n",
      "Epoch:  177 | train loss: 0.0024\n",
      "Epoch:  178 | train loss: 0.0000\n",
      "Epoch:  179 | train loss: 0.0442\n",
      "Epoch:  180 | train loss: 0.1240\n",
      "Epoch:  181 | train loss: 0.0032\n",
      "Epoch:  182 | train loss: 0.1105\n",
      "Epoch:  183 | train loss: 0.1146\n",
      "Epoch:  184 | train loss: 0.0010\n",
      "Epoch:  185 | train loss: 0.1916\n",
      "Epoch:  186 | train loss: 0.0332\n",
      "Epoch:  187 | train loss: 0.1339\n",
      "Epoch:  188 | train loss: 0.0016\n",
      "Epoch:  189 | train loss: 0.0410\n",
      "Epoch:  190 | train loss: 0.1987\n",
      "Epoch:  191 | train loss: 0.0516\n",
      "Epoch:  192 | train loss: 0.2488\n",
      "Epoch:  193 | train loss: 0.0056\n",
      "Epoch:  194 | train loss: 0.0102\n",
      "Epoch:  195 | train loss: 1.0167\n",
      "Epoch:  196 | train loss: 0.0130\n",
      "Epoch:  197 | train loss: 0.1875\n",
      "Epoch:  198 | train loss: 0.0417\n",
      "Epoch:  199 | train loss: 0.0011\n",
      "Epoch:  200 | train loss: 0.0230\n",
      "Epoch:  201 | train loss: 0.0027\n",
      "Epoch:  202 | train loss: 0.0048\n",
      "Epoch:  203 | train loss: 0.0043\n",
      "Epoch:  204 | train loss: 0.0053\n",
      "Epoch:  205 | train loss: 0.0055\n",
      "Epoch:  206 | train loss: 0.0046\n",
      "Epoch:  207 | train loss: 0.0001\n",
      "Epoch:  208 | train loss: 0.0055\n",
      "Epoch:  209 | train loss: 0.0027\n",
      "Epoch:  210 | train loss: 0.0021\n",
      "Epoch:  211 | train loss: 0.0012\n",
      "Epoch:  212 | train loss: 0.0012\n",
      "Epoch:  213 | train loss: 0.0012\n",
      "Epoch:  214 | train loss: 0.0007\n",
      "Epoch:  215 | train loss: 0.0007\n",
      "Epoch:  216 | train loss: 0.0003\n",
      "Epoch:  217 | train loss: 0.0002\n",
      "Epoch:  218 | train loss: 0.0000\n",
      "Epoch:  219 | train loss: 0.0017\n",
      "Epoch:  220 | train loss: 0.0134\n",
      "Epoch:  221 | train loss: 0.0200\n",
      "Epoch:  222 | train loss: 0.1114\n",
      "Epoch:  223 | train loss: 0.1499\n",
      "Epoch:  224 | train loss: 0.0401\n",
      "Epoch:  225 | train loss: 0.0226\n",
      "Epoch:  226 | train loss: 0.0016\n",
      "Epoch:  227 | train loss: 0.0000\n",
      "Epoch:  228 | train loss: 0.0089\n",
      "Epoch:  229 | train loss: 0.0063\n",
      "Epoch:  230 | train loss: 0.0025\n",
      "Epoch:  231 | train loss: 0.0205\n",
      "Epoch:  232 | train loss: 0.0974\n",
      "Epoch:  233 | train loss: 0.1874\n",
      "Epoch:  234 | train loss: 0.0266\n",
      "Epoch:  235 | train loss: 0.0010\n",
      "Epoch:  236 | train loss: 0.0003\n",
      "Epoch:  237 | train loss: 0.0100\n",
      "Epoch:  238 | train loss: 0.0004\n",
      "Epoch:  239 | train loss: 0.0074\n",
      "Epoch:  240 | train loss: 0.0431\n",
      "Epoch:  241 | train loss: 0.0118\n",
      "Epoch:  242 | train loss: 0.0067\n",
      "Epoch:  243 | train loss: 0.0052\n",
      "Epoch:  244 | train loss: 0.0066\n",
      "Epoch:  245 | train loss: 0.0054\n",
      "Epoch:  246 | train loss: 0.0033\n",
      "Epoch:  247 | train loss: 0.0011\n",
      "Epoch:  248 | train loss: 0.0263\n",
      "Epoch:  249 | train loss: 0.0001\n",
      "Epoch:  250 | train loss: 0.0164\n",
      "Epoch:  251 | train loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  252 | train loss: 0.0127\n",
      "Epoch:  253 | train loss: 0.0066\n",
      "Epoch:  254 | train loss: 0.0119\n",
      "Epoch:  255 | train loss: 0.0104\n",
      "Epoch:  256 | train loss: 0.0149\n",
      "Epoch:  257 | train loss: 0.0128\n",
      "Epoch:  258 | train loss: 0.0155\n",
      "Epoch:  259 | train loss: 0.0149\n",
      "Epoch:  260 | train loss: 0.0170\n",
      "Epoch:  261 | train loss: 0.0198\n",
      "Epoch:  262 | train loss: 0.0331\n",
      "Epoch:  263 | train loss: 0.0261\n",
      "Epoch:  264 | train loss: 0.0378\n",
      "Epoch:  265 | train loss: 0.0022\n",
      "Epoch:  266 | train loss: 0.2084\n",
      "Epoch:  267 | train loss: 0.0966\n",
      "Epoch:  268 | train loss: 0.0013\n",
      "Epoch:  269 | train loss: 0.1461\n",
      "Epoch:  270 | train loss: 0.0042\n",
      "Epoch:  271 | train loss: 0.1137\n",
      "Epoch:  272 | train loss: 0.0000\n",
      "Epoch:  273 | train loss: 0.0705\n",
      "Epoch:  274 | train loss: 0.0034\n",
      "Epoch:  275 | train loss: 0.0500\n",
      "Epoch:  276 | train loss: 0.0056\n",
      "Epoch:  277 | train loss: 0.0439\n",
      "Epoch:  278 | train loss: 0.0044\n",
      "Epoch:  279 | train loss: 0.0661\n",
      "Epoch:  280 | train loss: 0.0008\n",
      "Epoch:  281 | train loss: 0.0999\n",
      "Epoch:  282 | train loss: 0.0037\n",
      "Epoch:  283 | train loss: 0.0001\n",
      "Epoch:  284 | train loss: 0.0639\n",
      "Epoch:  285 | train loss: 2.0369\n",
      "Epoch:  286 | train loss: 0.4439\n",
      "Epoch:  287 | train loss: 0.0268\n",
      "Epoch:  288 | train loss: 0.0093\n",
      "Epoch:  289 | train loss: 0.4110\n",
      "Epoch:  290 | train loss: 0.0262\n",
      "Epoch:  291 | train loss: 0.1777\n",
      "Epoch:  292 | train loss: 0.0434\n",
      "Epoch:  293 | train loss: 0.0141\n",
      "Epoch:  294 | train loss: 0.0198\n",
      "Epoch:  295 | train loss: 0.0314\n",
      "Epoch:  296 | train loss: 0.0281\n",
      "Epoch:  297 | train loss: 0.0249\n",
      "Epoch:  298 | train loss: 0.0239\n",
      "Epoch:  299 | train loss: 0.0246\n",
      "Epoch:  300 | train loss: 0.0231\n",
      "Epoch:  301 | train loss: 0.0204\n",
      "Epoch:  302 | train loss: 0.0157\n",
      "Epoch:  303 | train loss: 0.0097\n",
      "Epoch:  304 | train loss: 0.0055\n",
      "Epoch:  305 | train loss: 0.0046\n",
      "Epoch:  306 | train loss: 0.0001\n",
      "Epoch:  307 | train loss: 0.0144\n",
      "Epoch:  308 | train loss: 0.0000\n",
      "Epoch:  309 | train loss: 0.0652\n",
      "Epoch:  310 | train loss: 0.0045\n",
      "Epoch:  311 | train loss: 0.0021\n",
      "Epoch:  312 | train loss: 0.0552\n",
      "Epoch:  313 | train loss: 0.0328\n",
      "Epoch:  314 | train loss: 0.1012\n",
      "Epoch:  315 | train loss: 0.0196\n",
      "Epoch:  316 | train loss: 0.0336\n",
      "Epoch:  317 | train loss: 0.0205\n",
      "Epoch:  318 | train loss: 0.0087\n",
      "Epoch:  319 | train loss: 0.0689\n",
      "Epoch:  320 | train loss: 0.0013\n",
      "Epoch:  321 | train loss: 0.0125\n",
      "Epoch:  322 | train loss: 0.0000\n",
      "Epoch:  323 | train loss: 0.0188\n",
      "Epoch:  324 | train loss: 0.0000\n",
      "Epoch:  325 | train loss: 0.1615\n",
      "Epoch:  326 | train loss: 0.2271\n",
      "Epoch:  327 | train loss: 0.0206\n",
      "Epoch:  328 | train loss: 0.0062\n",
      "Epoch:  329 | train loss: 0.2456\n",
      "Epoch:  330 | train loss: 0.0002\n",
      "Epoch:  331 | train loss: 0.0607\n",
      "Epoch:  332 | train loss: 0.0310\n",
      "Epoch:  333 | train loss: 0.0128\n",
      "Epoch:  334 | train loss: 0.0063\n",
      "Epoch:  335 | train loss: 0.0579\n",
      "Epoch:  336 | train loss: 0.1058\n",
      "Epoch:  337 | train loss: 0.1836\n",
      "Epoch:  338 | train loss: 0.2403\n",
      "Epoch:  339 | train loss: 0.2172\n",
      "Epoch:  340 | train loss: 0.9528\n",
      "Epoch:  341 | train loss: 2.1523\n",
      "Epoch:  342 | train loss: 0.8750\n",
      "Epoch:  343 | train loss: 0.0275\n",
      "Epoch:  344 | train loss: 0.0109\n",
      "Epoch:  345 | train loss: 0.6213\n",
      "Epoch:  346 | train loss: 1.2426\n",
      "Epoch:  347 | train loss: 0.2222\n",
      "Epoch:  348 | train loss: 0.4757\n",
      "Epoch:  349 | train loss: 0.0936\n",
      "Epoch:  350 | train loss: 0.0974\n",
      "Epoch:  351 | train loss: 0.0027\n",
      "Epoch:  352 | train loss: 0.0302\n",
      "Epoch:  353 | train loss: 0.0220\n",
      "Epoch:  354 | train loss: 0.0241\n",
      "Epoch:  355 | train loss: 0.0313\n",
      "Epoch:  356 | train loss: 0.0322\n",
      "Epoch:  357 | train loss: 0.0441\n",
      "Epoch:  358 | train loss: 0.0659\n",
      "Epoch:  359 | train loss: 0.0846\n",
      "Epoch:  360 | train loss: 0.0725\n",
      "Epoch:  361 | train loss: 0.0739\n",
      "Epoch:  362 | train loss: 0.0644\n",
      "Epoch:  363 | train loss: 0.0684\n",
      "Epoch:  364 | train loss: 0.0577\n",
      "Epoch:  365 | train loss: 0.0662\n",
      "Epoch:  366 | train loss: 0.0526\n",
      "Epoch:  367 | train loss: 0.0650\n",
      "Epoch:  368 | train loss: 0.0476\n",
      "Epoch:  369 | train loss: 0.0653\n",
      "Epoch:  370 | train loss: 0.0430\n",
      "Epoch:  371 | train loss: 0.0675\n",
      "Epoch:  372 | train loss: 0.0388\n",
      "Epoch:  373 | train loss: 0.0715\n",
      "Epoch:  374 | train loss: 0.0349\n",
      "Epoch:  375 | train loss: 0.0772\n",
      "Epoch:  376 | train loss: 0.0310\n",
      "Epoch:  377 | train loss: 0.0845\n",
      "Epoch:  378 | train loss: 0.0270\n",
      "Epoch:  379 | train loss: 0.0933\n",
      "Epoch:  380 | train loss: 0.0229\n",
      "Epoch:  381 | train loss: 0.1036\n",
      "Epoch:  382 | train loss: 0.0188\n",
      "Epoch:  383 | train loss: 0.1150\n",
      "Epoch:  384 | train loss: 0.0150\n",
      "Epoch:  385 | train loss: 0.1270\n",
      "Epoch:  386 | train loss: 0.0117\n",
      "Epoch:  387 | train loss: 0.1388\n",
      "Epoch:  388 | train loss: 0.0090\n",
      "Epoch:  389 | train loss: 0.1496\n",
      "Epoch:  390 | train loss: 0.0072\n",
      "Epoch:  391 | train loss: 0.1587\n",
      "Epoch:  392 | train loss: 0.0060\n",
      "Epoch:  393 | train loss: 0.1656\n",
      "Epoch:  394 | train loss: 0.0055\n",
      "Epoch:  395 | train loss: 0.1708\n",
      "Epoch:  396 | train loss: 0.0053\n",
      "Epoch:  397 | train loss: 0.1721\n",
      "Epoch:  398 | train loss: 0.0015\n",
      "Epoch:  399 | train loss: 0.1505\n",
      "Epoch:  400 | train loss: 0.1598\n",
      "Epoch:  401 | train loss: 0.9860\n",
      "Epoch:  402 | train loss: 0.0064\n",
      "Epoch:  403 | train loss: 0.0020\n",
      "Epoch:  404 | train loss: 0.5052\n",
      "Epoch:  405 | train loss: 0.0483\n",
      "Epoch:  406 | train loss: 0.0381\n",
      "Epoch:  407 | train loss: 0.0449\n",
      "Epoch:  408 | train loss: 0.1257\n",
      "Epoch:  409 | train loss: 0.0258\n",
      "Epoch:  410 | train loss: 0.1092\n",
      "Epoch:  411 | train loss: 0.0242\n",
      "Epoch:  412 | train loss: 0.0977\n",
      "Epoch:  413 | train loss: 0.0329\n",
      "Epoch:  414 | train loss: 0.0919\n",
      "Epoch:  415 | train loss: 0.0371\n",
      "Epoch:  416 | train loss: 0.0871\n",
      "Epoch:  417 | train loss: 0.0402\n",
      "Epoch:  418 | train loss: 0.0830\n",
      "Epoch:  419 | train loss: 0.0430\n",
      "Epoch:  420 | train loss: 0.0740\n",
      "Epoch:  421 | train loss: 0.0154\n",
      "Epoch:  422 | train loss: 0.1207\n",
      "Epoch:  423 | train loss: 0.0186\n",
      "Epoch:  424 | train loss: 0.0035\n",
      "Epoch:  425 | train loss: 0.2454\n",
      "Epoch:  426 | train loss: 0.0083\n",
      "Epoch:  427 | train loss: 0.1153\n",
      "Epoch:  428 | train loss: 0.0802\n",
      "Epoch:  429 | train loss: 0.0164\n",
      "Epoch:  430 | train loss: 0.1648\n",
      "Epoch:  431 | train loss: 0.0030\n",
      "Epoch:  432 | train loss: 0.2663\n",
      "Epoch:  433 | train loss: 0.0131\n",
      "Epoch:  434 | train loss: 0.0926\n",
      "Epoch:  435 | train loss: 0.1245\n",
      "Epoch:  436 | train loss: 0.0051\n",
      "Epoch:  437 | train loss: 0.2439\n",
      "Epoch:  438 | train loss: 0.0026\n",
      "Epoch:  439 | train loss: 0.1774\n",
      "Epoch:  440 | train loss: 0.0467\n",
      "Epoch:  441 | train loss: 0.0560\n",
      "Epoch:  442 | train loss: 0.1442\n",
      "Epoch:  443 | train loss: 0.0174\n",
      "Epoch:  444 | train loss: 0.1707\n",
      "Epoch:  445 | train loss: 0.0361\n",
      "Epoch:  446 | train loss: 0.0974\n",
      "Epoch:  447 | train loss: 0.1111\n",
      "Epoch:  448 | train loss: 0.0304\n",
      "Epoch:  449 | train loss: 0.1880\n",
      "Epoch:  450 | train loss: 0.0224\n",
      "Epoch:  451 | train loss: 0.1490\n",
      "Epoch:  452 | train loss: 0.0845\n",
      "Epoch:  453 | train loss: 0.0397\n",
      "Epoch:  454 | train loss: 0.2283\n",
      "Epoch:  455 | train loss: 0.0045\n",
      "Epoch:  456 | train loss: 0.2418\n",
      "Epoch:  457 | train loss: 0.0473\n",
      "Epoch:  458 | train loss: 0.0490\n",
      "Epoch:  459 | train loss: 0.2752\n",
      "Epoch:  460 | train loss: 0.0121\n",
      "Epoch:  461 | train loss: 0.4501\n",
      "Epoch:  462 | train loss: 0.0114\n",
      "Epoch:  463 | train loss: 0.0544\n",
      "Epoch:  464 | train loss: 0.3559\n",
      "Epoch:  465 | train loss: 0.0301\n",
      "Epoch:  466 | train loss: 0.4512\n",
      "Epoch:  467 | train loss: 0.0199\n",
      "Epoch:  468 | train loss: 0.0316\n",
      "Epoch:  469 | train loss: 0.2757\n",
      "Epoch:  470 | train loss: 0.0000\n",
      "Epoch:  471 | train loss: 0.2044\n",
      "Epoch:  472 | train loss: 0.0684\n",
      "Epoch:  473 | train loss: 0.0367\n",
      "Epoch:  474 | train loss: 0.2025\n",
      "Epoch:  475 | train loss: 0.0042\n",
      "Epoch:  476 | train loss: 0.1705\n",
      "Epoch:  477 | train loss: 0.0897\n",
      "Epoch:  478 | train loss: 0.0290\n",
      "Epoch:  479 | train loss: 0.2323\n",
      "Epoch:  480 | train loss: 0.0141\n",
      "Epoch:  481 | train loss: 0.1335\n",
      "Epoch:  482 | train loss: 0.1134\n",
      "Epoch:  483 | train loss: 0.0121\n",
      "Epoch:  484 | train loss: 0.1924\n",
      "Epoch:  485 | train loss: 0.0139\n",
      "Epoch:  486 | train loss: 0.3801\n",
      "Epoch:  487 | train loss: 0.1070\n",
      "Epoch:  488 | train loss: 0.0007\n",
      "Epoch:  489 | train loss: 0.6580\n",
      "Epoch:  490 | train loss: 0.0552\n",
      "Epoch:  491 | train loss: 0.2230\n",
      "Epoch:  492 | train loss: 0.1239\n",
      "Epoch:  493 | train loss: 0.0000\n",
      "Epoch:  494 | train loss: 0.3084\n",
      "Epoch:  495 | train loss: 0.0126\n",
      "Epoch:  496 | train loss: 0.0691\n",
      "Epoch:  497 | train loss: 0.2410\n",
      "Epoch:  498 | train loss: 0.0123\n",
      "Epoch:  499 | train loss: 0.3544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "    for x in range(12):\n",
    "        hidden_state = rnn.init_hidden() \n",
    "        if x == 0:\n",
    "            dailyInputs = inputs[:int(splitInputs[x])]            \n",
    "        else:           \n",
    "            dailyInputs = inputs[int(sum(splitInputs[:x])) :int(sum(splitInputs[:x])) + int(splitInputs[x])]\n",
    "        for y in range(int(splitInputs[x])):            \n",
    "            output, hidden_state = rnn(dailyInputs[y].view(1,3), hidden_state)                               # rnn output\n",
    "       \n",
    "        loss = loss_fn(output, outputs[x].view(1, 1))                   #  loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "    \n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "007b6cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3252, grad_fn=<SelectBackward0>)  :  tensor(0.0035) train loss: 0.3544\n",
      "train loss: 0.1035\n",
      "tensor(0.1365, grad_fn=<SelectBackward0>)  :  tensor(0.3937) train loss: 0.1035\n",
      "train loss: 0.0661\n",
      "tensor(-0.3840, grad_fn=<SelectBackward0>)  :  tensor(-0.7536) train loss: 0.0661\n",
      "train loss: 0.1366\n",
      "tensor(0.0406, grad_fn=<SelectBackward0>)  :  tensor(-0.4213) train loss: 0.1366\n",
      "train loss: 0.2134\n",
      "tensor(-0.7930, grad_fn=<SelectBackward0>)  :  tensor(-1.) train loss: 0.2134\n",
      "train loss: 0.0428\n",
      "tensor(-0.1577, grad_fn=<SelectBackward0>)  :  tensor(-0.5442) train loss: 0.0428\n",
      "train loss: 0.1494\n",
      "tensor(0.1696, grad_fn=<SelectBackward0>)  :  tensor(0.1144) train loss: 0.1494\n",
      "train loss: 0.0031\n",
      "tensor(0.3043, grad_fn=<SelectBackward0>)  :  tensor(1.) train loss: 0.0031\n",
      "train loss: 0.4840\n",
      "tensor(-0.3531, grad_fn=<SelectBackward0>)  :  tensor(-0.4547) train loss: 0.4840\n",
      "train loss: 0.0103\n",
      "tensor(-0.3986, grad_fn=<SelectBackward0>)  :  tensor(-0.4942) train loss: 0.0103\n",
      "train loss: 0.0091\n",
      "tensor(-0.4915, grad_fn=<SelectBackward0>)  :  tensor(-0.5029) train loss: 0.0091\n",
      "train loss: 0.0001\n",
      "tensor(-0.6917, grad_fn=<SelectBackward0>)  :  tensor(-0.2331) train loss: 0.0001\n",
      "train loss: 0.2103\n",
      "tensor(-0.6713, grad_fn=<SelectBackward0>)  :  tensor(-0.7753) train loss: 0.2103\n",
      "train loss: 0.0108\n",
      "tensor(-0.2475, grad_fn=<SelectBackward0>)  :  tensor(0.6089) train loss: 0.0108\n",
      "train loss: 0.7334\n",
      "tensor(-3.4242, grad_fn=<SelectBackward0>)  :  tensor(0.0772) train loss: 0.7334\n",
      "train loss: 12.2599\n"
     ]
    }
   ],
   "source": [
    "for x in range(15):\n",
    "    hidden_state = rnn.init_hidden()\n",
    "\n",
    "    if x == 0:\n",
    "        dailyInputs = inputs[:int(splitInputs[x])]            \n",
    "    else:           \n",
    "        dailyInputs = inputs[int(sum(splitInputs[:x])) :int(sum(splitInputs[:x])) + int(splitInputs[x])]\n",
    "    \n",
    "    for y in range(int(splitInputs[x])):            \n",
    "        output, hidden_state = rnn(dailyInputs[y].view(1,3), hidden_state)\n",
    "    print(output[0][0], \" : \", outputs[x][0], 'train loss: %.4f' % loss.data)\n",
    "    loss = loss_fn(output, outputs[x].view(1, 1))  \n",
    "    print('train loss: %.4f' % loss.data)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca3b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
