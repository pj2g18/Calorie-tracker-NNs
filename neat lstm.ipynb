{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight-2021-03-05.json']\n",
      "[{'weight': 116.6, 'fat': 16.0, 'date': '03/11/21'}\n",
      " {'weight': 116.6, 'fat': 16.0, 'date': '03/12/21'}\n",
      " {'weight': 114.6, 'fat': 15.300000190734863, 'date': '03/13/21'}\n",
      " {'weight': 114.6, 'fat': 14.5, 'date': '03/14/21'}\n",
      " {'weight': 112.0, 'fat': 13.899999618530273, 'date': '03/15/21'}\n",
      " {'weight': 112.8, 'fat': 13.199999809265137, 'date': '03/16/21'}\n",
      " {'weight': 112.8, 'fat': 13.199999809265137, 'date': '03/17/21'}\n",
      " {'weight': 112.0, 'fat': 14.600000381469727, 'date': '03/18/21'}\n",
      " {'weight': 112.2, 'fat': 14.600000381469727, 'date': '03/19/21'}\n",
      " {'weight': 110.0, 'fat': 14.600000381469727, 'date': '03/20/21'}\n",
      " {'weight': 110.8, 'fat': 13.899999618530273, 'date': '03/21/21'}\n",
      " {'weight': 109.8, 'fat': 13.899999618530273, 'date': '03/22/21'}\n",
      " {'weight': 109.8, 'fat': 13.899999618530273, 'date': '03/23/21'}\n",
      " {'weight': 110.4, 'fat': 14.600000381469727, 'date': '03/24/21'}\n",
      " {'weight': 107.6, 'fat': 14.600000381469727, 'date': '03/25/21'}\n",
      " {'weight': 109.8, 'fat': 13.199999809265137, 'date': '03/26/21'}\n",
      " {'weight': 108.7, 'fat': 13.199999809265137, 'date': '03/27/21'}]\n"
     ]
    }
   ],
   "source": [
    "#get weight data\n",
    "rootdir = \"MyFitbitData5/Mad/personal & Account\"\n",
    "#rootdir = \"MyFitbitData/name/personal & Account\"\n",
    "regex = re.compile('weight-2021-03-05')\n",
    "#regex = re.compile('weight-2021-most-recent')\n",
    "\n",
    "filenames = os.listdir(rootdir)\n",
    "weights= []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            weights = np.append(weights, file)\n",
    "\n",
    "print(weights)            \n",
    "for x in range(np.size(weights)):\n",
    "    filename = rootdir + \"/\" + weights[x]    \n",
    "    data = []\n",
    "    weight = []\n",
    "    fat = []\n",
    "    with open(filename) as json_file:\n",
    "        roughdata = json.load(json_file)\n",
    "        for x in range(np.size(roughdata)):\n",
    "            del roughdata[x][\"logId\"]\n",
    "            del roughdata[x][\"time\"]\n",
    "            del roughdata[x][\"source\"]\n",
    "            del roughdata[x][\"bmi\"]\n",
    "            weight = np.append(weight, roughdata[x][\"weight\"])\n",
    "            fat = np.append(fat, roughdata[x][\"fat\"])\n",
    "\n",
    "        data = np.append(data, roughdata)\n",
    "weightfat = data\n",
    "print(weightfat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyFitbitData5/Mad/Nutrition/food_logs-0.json\n",
      "{'logDate': '2021-03-26', 'calories': 140}\n",
      "{'logDate': '2021-03-25', 'calories': 211}\n",
      "{'logDate': '2021-03-24', 'calories': 177}\n",
      "{'logDate': '2021-03-23', 'calories': 283}\n",
      "{'logDate': '2021-03-22', 'calories': 167}\n",
      "{'logDate': '2021-03-21', 'calories': 80}\n",
      "{'logDate': '2021-03-20', 'calories': 226}\n",
      "{'logDate': '2021-03-19', 'calories': 409}\n",
      "{'logDate': '2021-03-18', 'calories': 275}\n",
      "{'logDate': '2021-03-17', 'calories': 252}\n",
      "{'logDate': '2021-03-16', 'calories': 342}\n",
      "{'logDate': '2021-03-15', 'calories': 180}\n",
      "{'logDate': '2021-03-14', 'calories': 340}\n",
      "{'logDate': '2021-03-13', 'calories': 423}\n",
      "{'logDate': '2021-03-12', 'calories': 266}\n",
      "[[1000.]\n",
      " [ 567.]\n",
      " [1052.]\n",
      " [ 932.]\n",
      " [ 601.]\n",
      " [ 810.]\n",
      " [ 775.]\n",
      " [ 757.]\n",
      " [1021.]\n",
      " [2191.]\n",
      " [ 658.]\n",
      " [ 744.]\n",
      " [1097.]\n",
      " [ 632.]\n",
      " [ 857.]\n",
      " [1611.]\n",
      " [1261.]]\n"
     ]
    }
   ],
   "source": [
    "#get calorie data\n",
    "rootdir = \"MyFitbitData5/Mad/Nutrition\"\n",
    "\n",
    "regex = re.compile('food_logs-0')\n",
    "filenames = os.listdir(rootdir)\n",
    "foodNames = []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            foodNames = np.append(foodNames, file)\n",
    "\n",
    "start = False\n",
    "#127\n",
    "for x in range(np.size(foodNames)):\n",
    "    filename = 'MyFitbitData5/Mad/Nutrition/' + foodNames[x]\n",
    "    data = []\n",
    "    count = 0\n",
    "    print(filename)\n",
    "    with open(filename) as json_file:\n",
    "        roughdata = json.load(json_file)\n",
    "        \n",
    "        for y in range(np.size(roughdata)):\n",
    "            \n",
    "            if roughdata[y-count][\"logDate\"] == \"2021-03-27\":\n",
    "                start = True\n",
    "            if roughdata[y-count][\"logDate\"] == \"2021-03-10\":\n",
    "                start = False\n",
    "            \n",
    "            if start == True:\n",
    "                cal = roughdata[y-count][\"loggedFood\"][\"calories\"]\n",
    "                del roughdata[y-count][\"logId\"]\n",
    "                del roughdata[y-count][\"loggedFood\"]\n",
    "                del roughdata[y-count][\"favorite\"]\n",
    "                if \"nutritionalValues\" in roughdata[y-count].keys():                \n",
    "                    del roughdata[y-count][\"nutritionalValues\"]                \n",
    "                roughdata[y-count][\"calories\"] = cal\n",
    "            else:\n",
    "                del roughdata[y-count]\n",
    "                count +=1\n",
    "\n",
    "                \n",
    "        \n",
    "        data = np.append(data, roughdata)\n",
    "calories = data[0][\"calories\"]\n",
    "totCalories = np.empty((0,1))\n",
    "dates = np.empty((0,1))\n",
    "dates = np.vstack((dates, [data[0][\"logDate\"]]))\n",
    "for x in range(len(data)-1):\n",
    "    if data[x+1][\"logDate\"] == data[x][\"logDate\"]:\n",
    "        calories += data[x+1][\"calories\"]\n",
    "        if x == len(data)-2:\n",
    "            totCalories = np.vstack((totCalories, calories))\n",
    "    else:\n",
    "        dates = np.vstack((dates, data[x+1][\"logDate\"]))\n",
    "        totCalories = np.vstack((totCalories, calories))\n",
    "        print(data[x+1])\n",
    "        calories = data[x+1][\"calories\"]\n",
    "        \n",
    "    \n",
    "\n",
    "totCalories = np.flip(np.vstack((totCalories, [[1000]])))\n",
    "print(totCalories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.656      18.656      17.53380022 16.617      15.56799957 14.88959978\n",
      " 14.88959978 16.35200043 16.38120043 16.06000042 15.40119958 15.26219958\n",
      " 15.26219958 16.11840042 15.70960041 14.49359979 14.34839979]\n",
      "[  -0.         -557.8959766  -162.63119077 -572.6372691    91.65866162\n",
      "   -0.          488.58337522   58.17978814 -273.61167113   95.13531859\n",
      " -121.76220858   -0.          360.84063081 -348.23303598  367.29365004\n",
      " -131.07102722    0.        ]\n",
      "[1000.         1124.8959766  1214.63119077 1504.6372691   509.34133838\n",
      "  810.          286.41662478  698.82021186 1294.61167113 2095.86468141\n",
      "  779.76220858  744.          736.15936919  980.23303598  489.70634996\n",
      " 1742.07102722 1261.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def caloriesBurned(weight, fat):\n",
    "    fatMass = []\n",
    "    leanMass = []\n",
    "    for x in range(len(weight)):\n",
    "        fatMass = np.append(fatMass, weight[x]*fat[x]/100)\n",
    "        leanMass = np.append(leanMass, weight[x] - fatMass[x])\n",
    "    calories = [] \n",
    "    print(fatMass)\n",
    "    for x in range(len(weight) - 1):   \n",
    "        calories = np.append(calories, -(fatMass[x]-fatMass[x+1])*442.39)\n",
    "        if leanMass[x] >= leanMass[x+1]:\n",
    "            calories[x] -= (leanMass[x] - leanMass[x+1])*70\n",
    "        else:\n",
    "            calories[x] -= (leanMass[x]-leanMass[x+1])*265\n",
    "    calories = np.append(calories, [0])\n",
    "\n",
    "    return calories\n",
    "        \n",
    "    \n",
    "calories = caloriesBurned(weight, fat)\n",
    "print(calories)\n",
    "for x in range(len(calories)):\n",
    "    calories[x] = totCalories[x] - calories[x]\n",
    "\n",
    "#calories = np.append(calories, [2000,2000, 2000])\n",
    "print(calories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0000e+00 4.2000e+01 1.0000e+00]\n",
      " [1.5000e+01 4.3000e+01 1.0000e+00]\n",
      " [5.0000e+00 4.2000e+01 1.0000e+00]\n",
      " ...\n",
      " [5.0000e+00 5.1000e+01 1.7000e+01]\n",
      " [5.0000e+00 5.0000e+01 1.7000e+01]\n",
      " [8.6389e+04 5.1000e+01 1.7000e+01]]\n",
      "tensor([[[-0.9977, -0.8870, -1.0000],\n",
      "         [-0.9919, -0.8757, -1.0000],\n",
      "         [-0.9977, -0.8870, -1.0000],\n",
      "         ...,\n",
      "         [-0.9948, -0.8983, -1.0000],\n",
      "         [-0.9948, -0.9096, -1.0000],\n",
      "         [-0.9977, -0.9209, -1.0000]],\n",
      "\n",
      "        [[-0.9948, -0.9322, -1.0000],\n",
      "         [-0.9977, -0.9209, -1.0000],\n",
      "         [-0.9977, -0.9322, -1.0000],\n",
      "         ...,\n",
      "         [-0.9977, -0.9322, -1.0000],\n",
      "         [-0.9977, -0.9209, -1.0000],\n",
      "         [-0.9919, -0.9096, -1.0000]],\n",
      "\n",
      "        [[-0.9977, -0.9209, -1.0000],\n",
      "         [-0.9977, -0.9096, -1.0000],\n",
      "         [-0.9977, -0.9209, -1.0000],\n",
      "         ...,\n",
      "         [-0.9977, -0.8192, -1.0000],\n",
      "         [-0.9977, -0.8870, -1.0000],\n",
      "         [-0.9948, -0.9209, -1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9948, -0.8192,  1.0000],\n",
      "         [-0.9977, -0.8418,  1.0000],\n",
      "         [-0.9977, -0.8644,  1.0000],\n",
      "         ...,\n",
      "         [-0.9971, -0.5819,  1.0000],\n",
      "         [-0.9948, -0.5932,  1.0000],\n",
      "         [-0.9948, -0.6045,  1.0000]],\n",
      "\n",
      "        [[-0.9919, -0.5932,  1.0000],\n",
      "         [-0.9977, -0.5819,  1.0000],\n",
      "         [-0.9948, -0.6045,  1.0000],\n",
      "         ...,\n",
      "         [-0.9948, -0.6384,  1.0000],\n",
      "         [-0.9977, -0.6384,  1.0000],\n",
      "         [-0.9977, -0.6610,  1.0000]],\n",
      "\n",
      "        [[-0.9977, -0.6723,  1.0000],\n",
      "         [-0.9977, -0.6836,  1.0000],\n",
      "         [-0.9977, -0.7288,  1.0000],\n",
      "         ...,\n",
      "         [-0.9977, -0.7966,  1.0000],\n",
      "         [-0.9977, -0.7853,  1.0000],\n",
      "         [-0.9977, -0.7966,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "#get heart rates\n",
    "rootdir = \"MyFitbitData5/Mad/Physical Activity\"\n",
    "#rootdir = \"MyFitbitData/Name/Physical Activity\"\n",
    "regex = re.compile('heart_rate-2021-03')\n",
    "filenames = os.listdir(rootdir)\n",
    "heartRates = []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            heartRates = np.append(heartRates, file)\n",
    "\n",
    "\n",
    "#read files for hr data\n",
    "inputs = np.empty((0,3))\n",
    "dateTime = []\n",
    "start = False\n",
    "minInputs = np.empty((0,3))\n",
    "hrDates = np.empty((0,1))\n",
    "count = 1\n",
    "for x in range(np.size(heartRates)):\n",
    "    filename = 'MyFitbitData5/Mad/Physical Activity/' + heartRates[x]\n",
    "    data = []\n",
    "    \n",
    "    with open(filename) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        inputs = np.empty((len(data), 3))\n",
    "        for y in range(len(data)):\n",
    "            temp = data[y][\"dateTime\"][9:] \n",
    "            \n",
    "            \n",
    "            if data[y][\"dateTime\"][:8] == \"03/11/21\":\n",
    "                start = True\n",
    "                \n",
    "            if data[y][\"dateTime\"][:8] == \"03/28/21\":\n",
    "                start = False\n",
    "            if start == True:\n",
    "                inputs[y][0] = int(temp[:2])*3600  + int(temp[3:5])*60 + int(temp[6:9])\n",
    "                inputs[y][1] = int(data[y][\"value\"][\"bpm\"])\n",
    "                inputs[y][2] = count\n",
    "            \n",
    "       # hrDates = np.vstack((hrDates, data[10][\"dateTime\"][:8]))\n",
    "        if start == True:\n",
    "            count += 1\n",
    "            minInputs = np.vstack((minInputs, inputs))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "for x in range(len(minInputs) - 1):\n",
    "    if minInputs[x][0] <= minInputs [x+1][0]:\n",
    "        minInputs[x][0] = minInputs[x+1][0] - minInputs[x][0]\n",
    "    else:\n",
    "        minInputs[x][0] = 86400 - minInputs[x][0] + minInputs[x+1][0]\n",
    "        \n",
    "        \n",
    "print(minInputs)    \n",
    "'''if minInputs[x][0] > 10:\n",
    "        tot = int(minInputs[x][0]/10)\n",
    "        print(tot)\n",
    "        print(minInputs[x])\n",
    "        \n",
    "        minInputs[x][0] = minInputs[x][0]%10\n",
    "        \n",
    "        for y in range(tot):    \n",
    "            intervals = minInputs[0:x+y, 0:1]\n",
    "            currentInterval = np.sum(intervals)           \n",
    "            minInputs = np.insert(minInputs, [x+1],[currentInterval, (minInputs[x][1]+minInputs[x+1][1])/2,int((currentInterval+((tot-y)*10))/86400)], axis=0)'''\n",
    "\n",
    "minInputs = np.delete(minInputs, len(minInputs)-1, 0)\n",
    "train_data_normalized2 = scaler.fit_transform(np.transpose(minInputs)[1] .reshape(-1,1))\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "train_data_normalized1 = scaler.fit_transform(np.transpose(minInputs)[0] .reshape(-1,1))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "train_data_normalized3 = scaler.fit_transform(np.transpose(minInputs)[2] .reshape(-1,1))\n",
    "\n",
    "train_data_normalized = np.hstack((train_data_normalized1, train_data_normalized2))\n",
    "\n",
    "train_data_normalized = np.hstack((train_data_normalized, train_data_normalized3))\n",
    "train_data_normalized =torch.FloatTensor(train_data_normalized)\n",
    "inputs = train_data_normalized.view(-1, 404, train_data_normalized.shape[1])\n",
    "print(inputs)\n",
    "numOfInputs = np.size(np.transpose(minInputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9976],\n",
      "        [-0.9924],\n",
      "        [-0.9976],\n",
      "        ...,\n",
      "        [-0.9969],\n",
      "        [-0.9969],\n",
      "        [-0.9969]])\n",
      "tensor([[[-0.9976],\n",
      "         [-0.9924],\n",
      "         [-0.9976],\n",
      "         ...,\n",
      "         [-0.9950],\n",
      "         [-0.9950],\n",
      "         [-0.9976]],\n",
      "\n",
      "        [[-0.9950],\n",
      "         [-0.9976],\n",
      "         [-0.9976],\n",
      "         ...,\n",
      "         [-0.9976],\n",
      "         [-0.9976],\n",
      "         [-0.9924]],\n",
      "\n",
      "        [[-0.9976],\n",
      "         [-0.9976],\n",
      "         [-0.9976],\n",
      "         ...,\n",
      "         [-0.9976],\n",
      "         [-0.9976],\n",
      "         [-0.9950]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9936],\n",
      "         [-0.9969],\n",
      "         [-0.9969],\n",
      "         ...,\n",
      "         [-0.9962],\n",
      "         [-0.9936],\n",
      "         [-0.9936]],\n",
      "\n",
      "        [[-0.9904],\n",
      "         [-0.9969],\n",
      "         [-0.9936],\n",
      "         ...,\n",
      "         [-0.9936],\n",
      "         [-0.9969],\n",
      "         [-0.9969]],\n",
      "\n",
      "        [[-0.9969],\n",
      "         [-0.9969],\n",
      "         [-0.9969],\n",
      "         ...,\n",
      "         [-0.9969],\n",
      "         [-0.9969],\n",
      "         [-0.9969]]])\n"
     ]
    }
   ],
   "source": [
    "y_actual = []\n",
    "\n",
    "for x in range(numOfInputs):\n",
    "    interval = minInputs[x][0]\n",
    "    day = minInputs[x][2]\n",
    "   \n",
    "    intervalCalorie = calories[int(day-1)]/86400 * interval        \n",
    "    y_actual = np.append(y_actual, intervalCalorie)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "normalized_y = torch.FloatTensor(scaler.fit_transform(y_actual .reshape(-1,1)))\n",
    "outputs = normalized_y.view(-1, 404, normalized_y.shape[1])\n",
    "print(normalized_y)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "'''class RNN(nn.Module):\n",
    "    def __init__(self, input_size = 3, hidden_size = 10, output_size = 1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, 1)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)        \n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq),1,-1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out)\n",
    "        return predictions\n",
    "    \n",
    "n_hidden = 5\n",
    "lstm = RNN()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.001)\n",
    "print(lstm)'''\n",
    "\n",
    "class RNN(nn.Module):\n",
    " \n",
    "    def __init__(self, input_dim=3, hidden_dim=20, batch_size=404, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    " \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    " \n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    " \n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    " \n",
    "    def forward(self, input_seq):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(input_seq.view(len(input_seq),1,-1))     \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.linear(lstm_out)\n",
    "        return y_pred\n",
    "lstm = RNN()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optimiser = torch.optim.Adam(lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for i in range(epochs):\n",
    "    for x in range(40): \n",
    "        lstm.zero_grad()\n",
    "\n",
    "        y_pred = lstm(inputs[x])\n",
    "        \n",
    "        single_loss = loss_function(y_pred.float(), outputs[x].view(404, 1, -1).float())\n",
    "        loss = loss_fn(y_pred, outputs[x])\n",
    "      \n",
    "        # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "print(\"WOOOOO\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.518486\n",
      "35.048713621699974\n",
      "[[0.10183563 0.03905909]\n",
      " [0.13930278 0.03905909]\n",
      " [0.09947445 0.03905909]\n",
      " [0.12784605 0.01301925]\n",
      " [0.14493883 0.03905909]\n",
      " [0.15299626 0.02603984]\n",
      " [0.15765172 0.03905909]\n",
      " [0.15820022 0.02603984]\n",
      " [0.16197008 0.03905909]\n",
      " [0.1644289  0.02603984]\n",
      " [0.16923955 0.03905909]\n",
      " [0.17184019 0.02603984]\n",
      " [0.17686892 0.03905909]\n",
      " [0.17585087 0.01301925]\n",
      " [0.17654651 0.03905909]\n",
      " [0.17729433 0.03905909]\n",
      " [0.176493   0.01301925]\n",
      " [0.17827357 0.02603984]\n",
      " [0.17819466 0.03905909]\n",
      " [0.17645554 0.01301925]\n",
      " [0.18413171 0.03905909]\n",
      " [0.17893578 0.02603984]\n",
      " [0.18058124 0.03905909]\n",
      " [0.17617193 0.02603984]\n",
      " [0.17153117 0.03905909]\n",
      " [0.16824558 0.02603984]\n",
      " [0.16892652 0.01301925]\n",
      " [0.16744694 0.02603984]\n",
      " [0.16539478 0.02603984]\n",
      " [0.17034991 0.01301925]\n",
      " [0.16686366 0.02603984]\n",
      " [0.16250518 0.02603984]\n",
      " [0.1671486  0.02603984]\n",
      " [0.16324899 0.02603984]\n",
      " [0.15861493 0.01301925]\n",
      " [0.15371999 0.02603984]\n",
      " [0.15366782 0.03905909]\n",
      " [0.14912473 0.02603984]\n",
      " [0.15133341 0.02603984]\n",
      " [0.15431932 0.01301925]\n",
      " [0.1509013  0.02603984]\n",
      " [0.15323974 0.03905909]\n",
      " [0.15619756 0.09113743]\n",
      " [0.15749387 0.06509759]\n",
      " [0.16288511 0.06509759]\n",
      " [0.16339882 0.06509759]\n",
      " [0.16005972 0.06509759]\n",
      " [0.16104299 0.06509759]\n",
      " [0.16188312 0.06509759]\n",
      " [0.15687849 0.06509759]\n",
      " [0.15287319 0.06509759]\n",
      " [0.14645988 0.06509759]\n",
      " [0.13750078 0.06509759]\n",
      " [0.13337642 0.06509759]\n",
      " [0.13717571 0.13019652]\n",
      " [0.14685319 0.13019652]\n",
      " [0.15342435 0.06509759]\n",
      " [0.15440628 0.06509759]\n",
      " [0.15625776 0.06509759]\n",
      " [0.16065638 0.06509759]\n",
      " [0.16048782 0.06509759]\n",
      " [0.15692933 0.06509759]\n",
      " [0.15386581 0.13019652]\n",
      " [0.15132137 0.13019652]\n",
      " [0.14728796 0.06509759]\n",
      " [0.14063787 0.06509759]\n",
      " [0.14000243 0.06509759]\n",
      " [0.14895885 0.06509759]\n",
      " [0.15548185 0.06509759]\n",
      " [0.1524879  0.06509759]\n",
      " [0.14385122 0.06509759]\n",
      " [0.14524518 0.19529412]\n",
      " [0.14570671 0.19529412]\n",
      " [0.14314888 0.06509759]\n",
      " [0.16442624 0.19529412]\n",
      " [0.15841827 0.13019652]\n",
      " [0.14212549 0.06509759]\n",
      " [0.13907535 0.06509759]\n",
      " [0.13859642 0.06509759]\n",
      " [0.14022851 0.06509759]\n",
      " [0.13960779 0.06509759]\n",
      " [0.14392747 0.06509759]\n",
      " [0.1494565  0.13019652]\n",
      " [0.14616022 0.06509759]\n",
      " [0.14361309 0.06509759]\n",
      " [0.14332949 0.19529412]\n",
      " [0.13970812 0.06509759]\n",
      " [0.14155559 0.13019652]\n",
      " [0.14158368 0.19529412]\n",
      " [0.13956229 0.19529412]\n",
      " [0.13601853 0.05207834]\n",
      " [0.13501118 0.06509759]\n",
      " [0.13631016 0.19529412]\n",
      " [0.13652822 0.19529412]\n",
      " [0.13692421 0.19529412]\n",
      " [0.13706601 0.19529412]\n",
      " [0.13716367 0.19529412]\n",
      " [0.13665397 0.13019652]\n",
      " [0.13521452 0.06509759]\n",
      " [0.13444664 0.06509759]\n",
      " [0.13410951 0.06509759]\n",
      " [0.13406135 0.06509759]\n",
      " [0.13638641 0.19529412]\n",
      " [0.13314365 0.13019652]\n",
      " [0.13756633 0.19529412]\n",
      " [0.1367048  0.06509759]\n",
      " [0.13809609 0.06509759]\n",
      " [0.14119038 0.13019652]\n",
      " [0.14059506 0.06509759]\n",
      " [0.14048536 0.06509759]\n",
      " [0.1401643  0.06509759]\n",
      " [0.13879174 0.19529412]\n",
      " [0.1363436  0.06509759]\n",
      " [0.13594763 0.06509759]\n",
      " [0.13470617 0.06509759]\n",
      " [0.13225536 0.06509759]\n",
      " [0.13267542 0.06509759]\n",
      " [0.13517572 0.06509759]\n",
      " [0.13825797 0.13019652]\n",
      " [0.13690948 0.06509759]\n",
      " [0.13510215 0.06509759]\n",
      " [0.13512355 0.06509759]\n",
      " [0.13905394 0.06509759]\n",
      " [0.14296293 0.19529412]\n",
      " [0.13914625 0.06509759]\n",
      " [0.1376573  0.06509759]\n",
      " [0.13893622 0.06509759]\n",
      " [0.13917166 0.06509759]\n",
      " [0.13979775 0.06509759]\n",
      " [0.139474   0.06509759]\n",
      " [0.13764928 0.06509759]\n",
      " [0.13657638 0.06509759]\n",
      " [0.13839976 0.19529412]\n",
      " [0.13980711 0.06509759]\n",
      " [0.13909407 0.06509759]\n",
      " [0.13698573 0.06509759]\n",
      " [0.1387409  0.06509759]\n",
      " [0.13791817 0.06509759]\n",
      " [0.13668607 0.06509759]\n",
      " [0.13975494 0.06509759]\n",
      " [0.14215089 0.06509759]\n",
      " [0.14291209 0.06509759]\n",
      " [0.13879575 0.06509759]\n",
      " [0.13524127 0.06509759]\n",
      " [0.13844392 0.06509759]\n",
      " [0.14180441 0.13019652]\n",
      " [0.13750613 0.06509759]\n",
      " [0.13809341 0.06509759]\n",
      " [0.14010544 0.13019652]\n",
      " [0.13960244 0.06509759]\n",
      " [0.14007065 0.06509759]\n",
      " [0.13823789 0.13019652]\n",
      " [0.13781248 0.06509759]\n",
      " [0.13915026 0.06509759]\n",
      " [0.13585398 0.06509759]\n",
      " [0.13328545 0.06509759]\n",
      " [0.13687737 0.19529412]\n",
      " [0.13429146 0.06509759]\n",
      " [0.13535365 0.19529412]\n",
      " [0.13422322 0.06509759]\n",
      " [0.13288812 0.06509759]\n",
      " [0.13464998 0.06509759]\n",
      " [0.13874625 0.13019652]\n",
      " [0.13968135 0.06509759]\n",
      " [0.14139505 0.13019652]\n",
      " [0.14197163 0.06509759]\n",
      " [0.14321443 0.06509759]\n",
      " [0.14215758 0.06509759]\n",
      " [0.14120777 0.06509759]\n",
      " [0.14064322 0.06509759]\n",
      " [0.14128536 0.19529412]\n",
      " [0.13795027 0.02603984]\n",
      " [0.13668875 0.06509759]\n",
      " [0.1326005  0.06509759]\n",
      " [0.13255636 0.06509759]\n",
      " [0.13577639 0.06509759]\n",
      " [0.13567472 0.06509759]\n",
      " [0.13485867 0.06509759]\n",
      " [0.13815764 0.19529412]\n",
      " [0.13946865 0.06509759]\n",
      " [0.141581   0.06509759]\n",
      " [0.14138435 0.13019652]\n",
      " [0.13989674 0.06509759]\n",
      " [0.13753423 0.06509759]\n",
      " [0.13524529 0.06509759]\n",
      " [0.13440248 0.06509759]\n",
      " [0.13617505 0.06509759]\n",
      " [0.13449614 0.06509759]\n",
      " [0.13464062 0.19529412]\n",
      " [0.13574964 0.19529412]\n",
      " [0.1358085  0.06509759]\n",
      " [0.13559981 0.06509759]\n",
      " [0.13485466 0.06509759]\n",
      " [0.13480516 0.06509759]\n",
      " [0.13374832 0.06509759]\n",
      " [0.13365333 0.13019652]\n",
      " [0.13295367 0.06509759]\n",
      " [0.13468476 0.06509759]\n",
      " [0.13806532 0.06509759]\n",
      " [0.13989407 0.13019652]\n",
      " [0.13819508 0.06509759]\n",
      " [0.13908872 0.06509759]\n",
      " [0.1407984  0.06509759]\n",
      " [0.14187799 0.06509759]\n",
      " [0.14006664 0.06509759]\n",
      " [0.13855495 0.06509759]\n",
      " [0.14028202 0.06509759]\n",
      " [0.14169739 0.06509759]\n",
      " [0.142682   0.13019652]\n",
      " [0.13936163 0.13019652]\n",
      " [0.13751015 0.06509759]\n",
      " [0.13670614 0.06509759]\n",
      " [0.13688809 0.06509759]\n",
      " [0.13612421 0.13019652]\n",
      " [0.13646534 0.06509759]\n",
      " [0.14068604 0.06509759]\n",
      " [0.14285591 0.06509759]\n",
      " [0.14602643 0.19529412]\n",
      " [0.14409603 0.13019652]\n",
      " [0.14158769 0.06509759]\n",
      " [0.14158368 0.19529412]\n",
      " [0.14058837 0.06509759]\n",
      " [0.15480761 0.06509759]\n",
      " [0.15472601 0.07811818]\n",
      " [0.14903912 0.06509759]\n",
      " [0.15122771 0.06509759]\n",
      " [0.14741506 0.06509759]\n",
      " [0.14122382 0.13019652]\n",
      " [0.13666333 0.06509759]\n",
      " [0.13492556 0.06509759]\n",
      " [0.13598107 0.06509759]\n",
      " [0.13842118 0.06509759]\n",
      " [0.14080375 0.06509759]\n",
      " [0.14877959 0.06509759]\n",
      " [0.1481816  0.19529412]\n",
      " [0.14214554 0.19529412]\n",
      " [0.1396506  0.19529412]\n",
      " [0.13563725 0.19529412]\n",
      " [0.13320518 0.13019652]\n",
      " [0.13463928 0.19529412]\n",
      " [0.13155971 0.06509759]\n",
      " [0.13028614 0.06509759]\n",
      " [0.13160788 0.06509759]\n",
      " [0.1331597  0.06509759]\n",
      " [0.13370551 0.06509759]\n",
      " [0.13509546 0.06509759]\n",
      " [0.13611485 0.06509759]\n",
      " [0.13433962 0.19529412]\n",
      " [0.13116373 0.19529412]\n",
      " [0.13016576 0.06509759]\n",
      " [0.12974435 0.06509759]\n",
      " [0.12869152 0.06509759]\n",
      " [0.1295691  0.19529412]\n",
      " [0.12848416 0.13019652]\n",
      " [0.1283437  0.06509759]\n",
      " [0.12852563 0.06509759]\n",
      " [0.12750089 0.06509759]\n",
      " [0.1278059  0.06509759]\n",
      " [0.1296895  0.06509759]\n",
      " [0.12881728 0.06509759]\n",
      " [0.1276039  0.06509759]\n",
      " [0.13070086 0.19529412]\n",
      " [0.13101122 0.06509759]\n",
      " [0.13408008 0.13019652]\n",
      " [0.1324092  0.19529412]\n",
      " [0.13178179 0.13019652]\n",
      " [0.13436636 0.13019652]\n",
      " [0.13494429 0.06509759]\n",
      " [0.13683993 0.06509759]\n",
      " [0.14114623 0.06509759]\n",
      " [0.14000912 0.06509759]\n",
      " [0.13416436 0.06509759]\n",
      " [0.13036107 0.06509759]\n",
      " [0.12855774 0.06509759]\n",
      " [0.12873031 0.06509759]\n",
      " [0.12945138 0.07811818]\n",
      " [0.12850958 0.06509759]\n",
      " [0.12958515 0.13019652]\n",
      " [0.13182192 0.06509759]\n",
      " [0.13434897 0.06509759]\n",
      " [0.13628341 0.06509759]\n",
      " [0.13665932 0.06509759]\n",
      " [0.13624996 0.06509759]\n",
      " [0.13346203 0.13019652]\n",
      " [0.13080521 0.06509759]\n",
      " [0.12548219 0.06509759]\n",
      " [0.12598653 0.19529412]\n",
      " [0.12881459 0.06509759]\n",
      " [0.13080788 0.06509759]\n",
      " [0.13103932 0.06509759]\n",
      " [0.13155703 0.06509759]\n",
      " [0.13185669 0.06509759]\n",
      " [0.13214432 0.06509759]\n",
      " [0.13240117 0.06509759]\n",
      " [0.13429146 0.13019652]\n",
      " [0.13677838 0.06509759]\n",
      " [0.13822185 0.06509759]\n",
      " [0.13378444 0.06509759]\n",
      " [0.13312224 0.13019652]\n",
      " [0.13564797 0.13019652]\n",
      " [0.1369416  0.06509759]\n",
      " [0.13573626 0.06509759]\n",
      " [0.13644126 0.06509759]\n",
      " [0.13773757 0.06509759]\n",
      " [0.13696165 0.06509759]\n",
      " [0.13518776 0.06509759]\n",
      " [0.13458844 0.13019652]\n",
      " [0.13335769 0.06509759]\n",
      " [0.13296437 0.13019652]\n",
      " [0.13555565 0.06509759]\n",
      " [0.1413188  0.19529412]\n",
      " [0.13947801 0.06509759]\n",
      " [0.13924524 0.06509759]\n",
      " [0.13924927 0.13019652]\n",
      " [0.13929206 0.19529412]\n",
      " [0.13784058 0.19529412]\n",
      " [0.1356881  0.06509759]\n",
      " [0.13451353 0.06509759]\n",
      " [0.13525733 0.06509759]\n",
      " [0.13335367 0.06509759]\n",
      " [0.13425533 0.06509759]\n",
      " [0.1362125  0.06509759]\n",
      " [0.13458577 0.06509759]\n",
      " [0.13423526 0.06509759]\n",
      " [0.13566937 0.06509759]\n",
      " [0.1365523  0.06509759]\n",
      " [0.1368921  0.06509759]\n",
      " [0.13969073 0.13019652]\n",
      " [0.13633959 0.05207834]\n",
      " [0.13376704 0.06509759]\n",
      " [0.13521318 0.13019652]\n",
      " [0.13402122 0.13019652]\n",
      " [0.13104199 0.06509759]\n",
      " [0.13212426 0.19529412]\n",
      " [0.13196371 0.19529412]\n",
      " [0.13115838 0.06509759]\n",
      " [0.13383527 0.06509759]\n",
      " [0.13553292 0.06509759]\n",
      " [0.1378767  0.13019652]\n",
      " [0.13785931 0.13019652]\n",
      " [0.1348453  0.06509759]\n",
      " [0.13312358 0.06509759]\n",
      " [0.13536167 0.06509759]\n",
      " [0.13761984 0.19529412]\n",
      " [0.13544194 0.13019652]\n",
      " [0.13606134 0.13019652]\n",
      " [0.13274364 0.06509759]\n",
      " [0.13350484 0.06509759]\n",
      " [0.13509412 0.06509759]\n",
      " [0.13547941 0.06509759]\n",
      " [0.13630615 0.13019652]\n",
      " [0.13251622 0.06509759]\n",
      " [0.13177375 0.13019652]\n",
      " [0.13541518 0.13019652]\n",
      " [0.1360921  0.06509759]\n",
      " [0.13582188 0.07811818]\n",
      " [0.1366941  0.19529412]\n",
      " [0.13501921 0.06509759]\n",
      " [0.13657504 0.19529412]\n",
      " [0.13367875 0.06509759]\n",
      " [0.13484262 0.13019652]\n",
      " [0.13479981 0.13019652]\n",
      " [0.13240786 0.06509759]\n",
      " [0.1308721  0.06509759]\n",
      " [0.13067812 0.13019652]\n",
      " [0.12948883 0.06509759]\n",
      " [0.13016842 0.13019652]\n",
      " [0.12919453 0.06509759]\n",
      " [0.1300614  0.13019652]\n",
      " [0.13202526 0.06509759]\n",
      " [0.13439044 0.13019652]\n",
      " [0.13166405 0.06509759]\n",
      " [0.13053498 0.06509759]\n",
      " [0.12889218 0.06509759]\n",
      " [0.12869687 0.06509759]\n",
      " [0.12811092 0.06509759]\n",
      " [0.12761059 0.19529412]\n",
      " [0.12885472 0.06509759]\n",
      " [0.1322286  0.06509759]\n",
      " [0.13386604 0.06509759]\n",
      " [0.13361186 0.19529412]\n",
      " [0.13108346 0.06509759]\n",
      " [0.13091758 0.06509759]\n",
      " [0.13252692 0.06509759]\n",
      " [0.134757   0.19529412]\n",
      " [0.13321856 0.19529412]\n",
      " [0.13059784 0.06509759]\n",
      " [0.13044266 0.13019652]\n",
      " [0.12896711 0.06509759]\n",
      " [0.12898047 0.06509759]\n",
      " [0.13048413 0.06509759]\n",
      " [0.13009217 0.06509759]\n",
      " [0.12963866 0.13019652]\n",
      " [0.12975906 0.19529412]\n",
      " [0.13032094 0.19529412]\n",
      " [0.1313149  0.13019652]\n",
      " [0.13385266 0.19529412]\n",
      " [0.13249749 0.06509759]\n",
      " [0.13234633 0.13019652]\n",
      " [0.13131624 0.06509759]\n",
      " [0.13270485 0.06509759]\n",
      " [0.13314097 0.06509759]\n",
      " [0.13078113 0.06509759]\n",
      " [0.12844002 0.13019652]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([404, 1])) that is different to the input size (torch.Size([404, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "num = 45\n",
    "y_pred = lstm(inputs[num])\n",
    "single_loss = loss_function(y_pred.float(), outputs[0].float())\n",
    "yo = y_pred.detach().numpy()\n",
    "\n",
    "woo =scaler.inverse_transform(np.transpose(np.transpose(yo)[0]))\n",
    "print(np.sum(woo))\n",
    "#print(woo)\n",
    "outs = scaler.inverse_transform(outputs[num])\n",
    "print(np.sum(outs))\n",
    "print(np.hstack((woo,outs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
