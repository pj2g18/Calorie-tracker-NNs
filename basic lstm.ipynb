{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8332e+04 4.0000e+01 8.0000e+00]\n",
      "[1.8342e+04 4.1000e+01 8.0000e+00]\n",
      "[[1.5000e+01 8.2000e+01 1.0000e+00]\n",
      " [1.0000e+01 8.1000e+01 1.0000e+00]\n",
      " [5.0000e+00 7.4000e+01 1.0000e+00]\n",
      " ...\n",
      " [5.0000e+00 5.8000e+01 8.8000e+01]\n",
      " [5.0000e+00 5.7000e+01 8.8000e+01]\n",
      " [8.2795e+04 5.8000e+01 8.8000e+01]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numOfInputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e6eaea7a5ff0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mtrain_data_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_normalized3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0mtrain_data_normalized\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumOfInputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_normalized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m303\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_normalized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numOfInputs' is not defined"
     ]
    }
   ],
   "source": [
    "#get filenames\n",
    "rootdir = \"MyFitbitData5/Mad/Physical Activity\"\n",
    "regex = re.compile('heart_rate-2021')\n",
    "filenames = os.listdir(rootdir)\n",
    "heartRates = []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            heartRates = np.append(heartRates, file)\n",
    "\n",
    "\n",
    "#read files for hr data\n",
    "inputs = np.empty((0,3))\n",
    "dateTime = []\n",
    "minInputs = np.empty((0,3))\n",
    "for x in range(np.size(heartRates)):\n",
    "    filename = 'MyFitbitData5/Mad/Physical Activity/' + heartRates[x]\n",
    "    data = []\n",
    "    \n",
    "    with open(filename) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        inputs = np.empty((len(data), 3))\n",
    "        for y in range(len(data)):\n",
    "            temp = data[y][\"dateTime\"][9:] \n",
    "            inputs[y][0] = int(temp[:2])*3600  + int(temp[3:5])*60 + int(temp[6:9])\n",
    "            inputs[y][1] = int(data[y][\"value\"][\"bpm\"])\n",
    "            inputs[y][2] = x+1\n",
    "            if inputs[y][2] == 0:\n",
    "                print(\"Hello\")\n",
    "        minInputs = np.vstack((minInputs, inputs))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "for x in range(len(minInputs) - 1):\n",
    "    if x == 82529:\n",
    "        print(minInputs[x])\n",
    "        print(minInputs[x+1])\n",
    "    if minInputs[x][0] <= minInputs [x+1][0]:\n",
    "        minInputs[x][0] = minInputs[x+1][0] - minInputs[x][0]\n",
    "    else:\n",
    "        minInputs[x][0] = 86400 - minInputs[x][0] + minInputs[x+1][0]\n",
    "        \n",
    "        \n",
    "        \n",
    "    '''if minInputs[x][0] > 10:\n",
    "        tot = int(minInputs[x][0]/10)\n",
    "        print(tot)\n",
    "        print(minInputs[x])\n",
    "        \n",
    "        minInputs[x][0] = minInputs[x][0]%10\n",
    "        \n",
    "        for y in range(tot):    \n",
    "            intervals = minInputs[0:x+y, 0:1]\n",
    "            currentInterval = np.sum(intervals)           \n",
    "            minInputs = np.insert(minInputs, [x+1],[currentInterval, (minInputs[x][1]+minInputs[x+1][1])/2,int((currentInterval+((tot-y)*10))/86400)], axis=0)'''\n",
    "        \n",
    "print(minInputs)\n",
    "\n",
    "minInputs = np.delete(minInputs, len(minInputs)-1, 0)\n",
    "train_data_normalized2 = scaler.fit_transform(np.transpose(minInputs)[1] .reshape(-1,1))\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "train_data_normalized1 = scaler.fit_transform(np.transpose(minInputs)[0] .reshape(-1,1))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "train_data_normalized3 = scaler.fit_transform(np.transpose(minInputs)[2] .reshape(-1,1))\n",
    "\n",
    "train_data_normalized = np.hstack((train_data_normalized1, train_data_normalized2))\n",
    "\n",
    "train_data_normalized = np.hstack((train_data_normalized, train_data_normalized3))\n",
    "train_data_normalized =torch.FloatTensor(train_data_normalized)\n",
    "print(numOfInputs)\n",
    "inputs = train_data_normalized.view(-1, 303, train_data_normalized.shape[1])\n",
    "print(inputs)\n",
    "numOfInputs = np.size(np.transpose(minInputs)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"MyFitbitData5/Mad/Nutrition\"\n",
    "\n",
    "regex = re.compile('food_logs-0')\n",
    "filenames = os.listdir(rootdir)\n",
    "foodNames = []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            foodNames = np.append(foodNames, file)\n",
    "\n",
    "#127\n",
    "for x in range(np.size(foodNames)):\n",
    "    filename = 'MyFitbitData5/Mad/Nutrition/' + foodNames[x]\n",
    "    data = []\n",
    "    print(filename)\n",
    "    with open(filename) as json_file:\n",
    "        roughdata = json.load(json_file)\n",
    "        \n",
    "        for x in range(np.size(roughdata)):\n",
    "            \n",
    "            cal = roughdata[x][\"loggedFood\"][\"calories\"]\n",
    "            del roughdata[x][\"logId\"]\n",
    "            del roughdata[x][\"loggedFood\"]\n",
    "            del roughdata[x][\"favorite\"]\n",
    "            if \"nutritionalValues\" in roughdata[x].keys():                \n",
    "                del roughdata[x][\"nutritionalValues\"]\n",
    "\n",
    "                \n",
    "            roughdata[x][\"calories\"] = cal\n",
    "        data = np.append(data, roughdata)\n",
    "calories = data[0][\"calories\"]\n",
    "totCalories = np.empty((0,1))\n",
    "dates = \n",
    "for x in range(len(data)-1):\n",
    "    if data[x+1][\"logDate\"] == data[x][\"logDate\"]:\n",
    "        calories += data[x+1][\"calories\"]\n",
    "        if x == len(data)-2:\n",
    "            totCalories = np.vstack((totCalories, calories))\n",
    "    else:\n",
    "        totCalories = np.vstack((totCalories, calories))\n",
    "        calories = data[x+1][\"calories\"]\n",
    "        \n",
    "    \n",
    "totCalories[10][0] += 1050\n",
    "\n",
    "print(totCalories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"MyFitbitData5/Mad/personal & Account\"\n",
    "regex = re.compile('weight-2021-03-05')\n",
    "filenames = os.listdir(rootdir)\n",
    "weights= []\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex.match(file):\n",
    "            weights = np.append(weights, file)\n",
    "\n",
    "print(weights)            \n",
    "for x in range(np.size(weights)):\n",
    "    filename = 'MyFitbitData5/Mad/personal & Account/' + weights[x]\n",
    "    data = []\n",
    "    weight = []\n",
    "    fat = []\n",
    "    with open(filename) as json_file:\n",
    "        roughdata = json.load(json_file)\n",
    "        for x in range(np.size(roughdata)):\n",
    "            del roughdata[x][\"logId\"]\n",
    "            del roughdata[x][\"time\"]\n",
    "            del roughdata[x][\"source\"]\n",
    "            del roughdata[x][\"bmi\"]\n",
    "            weight = np.append(weight, roughdata[x][\"weight\"])\n",
    "            fat = np.append(fat, roughdata[x][\"fat\"])\n",
    "\n",
    "        data = np.append(data, roughdata)\n",
    "\n",
    "weightfat = data\n",
    "\n",
    "fat = np.insert(fat, 4, [])\n",
    "\n",
    "def caloriesBurned(weight, fat):\n",
    "    fatMass = []\n",
    "    leanMass = []\n",
    "    for x in range(len(weight)):\n",
    "        fatMass = np.append(fatMass, weight[x]*fat[x]/100)\n",
    "        leanMass = np.append(leanMass, weight[x] - fatMass[x])\n",
    "    calories = [] \n",
    "    print(fatMass)\n",
    "\n",
    "    for x in range(len(weight) - 1):   \n",
    "        calories = np.append(calories, -(fatMass[x]-fatMass[x+1])*442.39)\n",
    "        if leanMass[x] >= leanMass[x+1]:\n",
    "            calories[x] -= (leanMass[x] - leanMass[x+1])*70\n",
    "        else:\n",
    "            calories[x] -= (leanMass[x]-leanMass[x+1])*265\n",
    "    return calories\n",
    "        \n",
    "    \n",
    "calories = caloriesBurned(weight, fat)\n",
    "\n",
    "for x in range(len(calories)):\n",
    "    calories[x] = totCalories[x] - calories[x]\n",
    "\n",
    "#calories = np.append(calories, [2000,2000, 2000])\n",
    "print(calories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = []\n",
    "\n",
    "for x in range(numOfInputs):\n",
    "    interval = minInputs[x][0]\n",
    "    day = minInputs[x][2]\n",
    "   \n",
    "    intervalCalorie = calories[int(day-1)]/86400 * interval        \n",
    "    y_actual = np.append(y_actual, intervalCalorie)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "normalized_y = torch.FloatTensor(scaler.fit_transform(y_actual .reshape(-1,1)))\n",
    "outputs = normalized_y.view(-1, 303, normalized_y.shape[1])\n",
    "print(normalized_y)\n",
    "print(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size = 3, hidden_size = 5, output_size = 1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, 1)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_size),torch.zeros(1,1,self.hidden_size))\n",
    "        \n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq),1,-1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out)\n",
    "        return predictions\n",
    "    \n",
    "n_hidden = 5\n",
    "lstm = RNN()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.0001)\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-90cf7f5123fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized_y' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "print(normalized_y[0:3, 0:3])\n",
    "print(lstm(inputs[0]))\n",
    "print(np.sum(scaler.inverse_transform(outputs[0])))\n",
    "\n",
    "for i in range(epochs):\n",
    "    for x in range(len(inputs)-1):    \n",
    "        optimizer.zero_grad()\n",
    "        lstm.hidden_cell = (torch.zeros(1,1, lstm.hidden_size), torch.zeros(1,1,lstm.hidden_size))\n",
    "        y_pred = lstm(inputs[x])\n",
    "        single_loss = loss_function(y_pred.float(), outputs[x].float())\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4312e-06, grad_fn=<MseLossBackward>)\n",
      "33.841354\n",
      "53.471649915315595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([303, 1])) that is different to the input size (torch.Size([303, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm(inputs[len(inputs)-1])\n",
    "single_loss = loss_function(y_pred.float(), outputs[len(inputs) -1].float())\n",
    "print(single_loss)\n",
    "yo = y_pred.detach().numpy()\n",
    "\n",
    "woo =scaler.inverse_transform(np.transpose(np.transpose(yo)[0]))\n",
    "print(np.sum(woo))\n",
    "#print(woo)\n",
    "print(np.sum(scaler.inverse_transform(outputs[len(inputs) -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
